# Storm Hook
## 1. 介绍
Apache Storm是一个分布式实时计算系统。 Storm可以轻松可靠地处理无限数据流，实现Hadoop为批处理所做的实时处理。该过程本质上是节点的DAG，称为**拓扑**。

Apache Atlas是一个元数据存储库，支持端到端数据血缘，搜索和关联业务分类。

Storm Hook集成的目标是将操作拓扑元数据与基础数据源，目标，派生过程和任何可用业务上下文一起推送，以便Atlas可以捕获此拓扑的血缘。

该过程分为两部分，详述如下：
- 用于表示Storm中概念的数据模型
- Storm Atlas Hook更新Atlas中的元数据

## 2. Storm数据模型
数据模型在Atlas中表示为类型。它包含拓扑图中各种节点的描述，例如喷口和螺栓以及相应的生产者和消费者类型。

Atlas中添加了以下类型。
- `storm_topology`: 表示粗粒度拓扑。 storm_topology源自Atlas Process类型，因此可用于向Atlas通知谱系。

- 添加了以下数据集: `kafka_topic`，`jms_topic`，`hbase_table`，`hdfs_data_set`。这些都来自Atlas数据集类型，因此形成了血缘图的终点。
  - `storm_spout`: 具有输出的数据生成器，通常是Kafka，JMS
  - `storm_bolt`: 具有输入和输出的数据消费者，通常是Hive，HBase，HDFS等。

Storm Atlas hook自动注册依赖模型，如Hive数据模型，如果它发现Atlas服务器不知道这些模型。

`org.apache.atlas.storm.model.StormDataModel`的类定义中描述了每种类型的数据模型。

## 3. Storm hook
在Storm中成功注册新拓扑时会收到Atlas通知。 Storm在Storm客户端提供了一个 `hookbacktype.storm.ISubmitterHook`，用于提交Storm拓扑。

Storm Atlas hook拦截 hook后执行并从拓扑中提取元数据并使用定义的类型更新Atlas。 Atlas在`org.apache.atlas.storm.hook.StormAtlasHook`中实现了Storm客户端hook接口。

## 4. 限制
以下内容适用于集成的第一个版本。

- 只有新的拓扑提交在Atlas中注册，否则任何生命周期更改都不会反映在Atlas中。
- 提交Storm拓扑以捕获元数据时，Atlas服务器需要在线。
- Hook目前不支持捕获自定义spouts和bolts的血缘。

## 5. 安装
Storm Atlas Hook需要在客户端手动安装在Storm中。

- 解压`apache-atlas-${project.version}-storm-hook.tar.gz`
- `cd apache-atlas-storm-hook-${project.version}``
- 将文件夹`apache-atlas-storm-hook-${project.version}/hook/storm`到`$ ATLAS_PACKAGE/hook/storm`
- 需要将`$ATLAS_PACKAGE/hook/storm`中的Storm Atlas hook复制到`$STORM_HOME/extlib`。将STORM_HOME替换为Storm安装路径。

在将atlas hook安装到Storm后重新启动所有守护进程。

## 6. 配置
### 6.1 Storm 配置
需要在`$STORM_HOME/conf/storm.yaml`中的Storm客户端配置中配置Storm Atlas Hook，如下所示：
```
storm.topology.submission.notifier.plugin.class: "org.apache.atlas.storm.hook.StormAtlasHook"
```

还需要设置一个“cluster name”，该名称将用作Atlas中注册的对象的命名空间。此名称将用于命名空间Storm拓扑，spouts 和 bolts。

理想情况下，数据集等其他对象应使用生成它们的组件的集群名称进行标识。对于例如应使用Hive中设置的群集名称来标识Hive表和数据库。如果Hive配置在客户端上提交的Storm拓扑jar中可用并且在那里定义了集群名称，则Storm Atlas hook将选择此选项。对于HBase数据集，这种情况类似。如果此配置不可用，将使用Storm配置中设置的群集名称。
```
atlas.cluster.name: "cluster_name"
```

在`$STORM_HOME/conf/storm_env.ini`中，按如下方式设置环境变量：
```
STORM_JAR_JVM_OPTS:"-Datlas.conf=$ATLAS_HOME/conf/"
```

其中ATLAS_HOME指向ATLAS的安装位置。
你也可以在Storm Config中以编程方式设置它：
```
Config stormConf = new Config();
    ...
    stormConf.put(Config.STORM_TOPOLOGY_SUBMISSION_NOTIFIER_PLUGIN,
            org.apache.atlas.storm.hook.StormAtlasHook.class.getName());
```
